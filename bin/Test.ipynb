{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06cd0348",
   "metadata": {},
   "source": [
    "# TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405dacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "from crossevopred.src.model.dummy_model import DummyModel\n",
    "from crossevopred.src.model.dummy_trainer import DummyTrainer\n",
    "from crossevopred.utils.data_processing_utils import *\n",
    "\n",
    "fasta = \"/home/luisasantus/Desktop/crg_cluster/data/CrossEvoPred/test/chr1.fa\"\n",
    "bed = \"/home/luisasantus/Desktop/crg_cluster/data/CrossEvoPred/test/chr1.bed\"\n",
    "bedgraph = \"/home/luisasantus/Desktop/crg_cluster/data/CrossEvoPred/test/chr1.bedgraph\"\n",
    "binsize = 5\n",
    "training_dataset = \"/home/luisasantus/Desktop/PROJECTS/CrossEvoPred/out/data/training_set/objects/chr1.pth\"\n",
    "config_file = \"/home/luisasantus/Desktop/PROJECTS/CrossEvoPred/bin/crossevopred/config/test_config.yaml\"\n",
    "model_path = \"/home/luisasantus/Desktop/PROJECTS/CrossEvoPred/out/models/model.pkl\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19863668",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/luisasantus/Desktop/PROJECTS/CrossEvoPred/out/data/training_set/objects/chr1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model   \u001b[39m=\u001b[39m DummyModel()\n\u001b[1;32m      3\u001b[0m trainer \u001b[39m=\u001b[39m DummyTrainer()\n\u001b[0;32m----> 4\u001b[0m trainining_datatset_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(training_dataset)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel initialized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/luisasantus/Desktop/PROJECTS/CrossEvoPred/out/data/training_set/objects/chr1.pth'"
     ]
    }
   ],
   "source": [
    "# retrain model \n",
    "model   = DummyModel()\n",
    "trainer = DummyTrainer()\n",
    "trainining_datatset_loader = torch.load(training_dataset)\n",
    "print(\"Model initialized\")\n",
    "# Train the model\n",
    "trainer.train(trainining_datatset_loader, config_file=config_file, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a70abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff69b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a02640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "55c42ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 40])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainining_datatset_loader.sequences.reshape(trainining_datatset_loader.sequences.size(0),-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2027685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = get_sequences_from_bed(bed, fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ff1c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute length of all sequences\n",
    "lengths = [len(seq) for seq in sequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b194548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequence = dataset.sequences[0]\n",
    "test_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7430dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_sequence.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b2c1cd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACCCTAACC</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTAACCCTAA</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sequence  correlation\n",
       "0  AACCCTAACC         -0.0\n",
       "1  CTAACCCTAA         -0.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46ec66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch \n",
    "from crossevopred.src.data.encoder import DNAEncoder\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "training_file = \"../simulated/simulated\"\n",
    "training_dataset_file = training_file+ \"_test_dataset.pt\"\n",
    "trainining_datatset_loader = DataLoader(torch.load(training_dataset_file), batch_size = 32, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5584eedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainining_datatset_loader.dataset.sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a770d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2422, 3.3047, 3.2422, 3.2266, 3.2891, 3.2891, 3.3125],\n",
       "        [3.2109, 3.2891, 3.2188, 3.2188, 3.2812, 3.1406, 3.3203]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(trainining_datatset_loader.dataset.labels[1:3], [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89f75352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = DNAEncoder()\n",
    "one_hot_encoded_seq = encoder.encode_sequences([\"AATC\", \"AAAA\"])\n",
    "# make it a tensor\n",
    "one_hot_encoded_seq = torch.tensor(one_hot_encoded_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66403d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0fc18f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTTT'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = torch.flip(one_hot_encoded_seq, [1,2])\n",
    "encoder.decode_one_hot(rc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a293725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_tensor = tensor.flip(dims=(0,))\n",
    "reversed_tensor\n",
    "\n",
    "# now just invert a with t and c with g\n",
    "# swap first row with the last row\n",
    "reversed_tensor[0], reversed_tensor[-1] = reversed_tensor[-1], reversed_tensor[0]\n",
    "# swap second row with the second last row\n",
    "reversed_tensor[1], reversed_tensor[-2] = reversed_tensor[-2], reversed_tensor[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c4c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the complement mapping\n",
    "complement_mapping = torch.tensor([3, 2, 1, 0], dtype=torch.long)\n",
    "\n",
    "# Reverse the tensor along the 0th dimension\n",
    "reversed_tensor = transposed_tensor.flip(dims=(0,))\n",
    "\n",
    "# Complement each nucleotide using the mapping\n",
    "complemented_tensor = complement_mapping[reversed_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a21ee85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c77a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929097fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cb3457e621fef10ccc726cdf49c3a6d7ae9ec7c3c7d02b1814e28a4a388400d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
